import os  # Moved up as per PEP8

from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware

from app.api.chat_ops import chat
from app.api.file_ops import (background_tasks,  # Removed: embed, chunk
                              ingest, upload, ingestion_worker)
from app.api.project_ops import project, session_log
from app.core.config import settings

# üß™ Optional: Print env variables for debugging
print("üîç Environment Variable Check:")
print("OPENAI_API_KEY =", os.getenv("OPENAI_API_KEY"))
print("SUPABASE_URL =", os.getenv("SUPABASE_URL"))

app = FastAPI(
    title=settings.PROJECT_NAME, openapi_url=f"{settings.API_PREFIX}/openapi.json"
)

# ‚úÖ CORS middleware for local testing
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


@app.get("/")
async def root():
    return {"message": f"{settings.PROJECT_NAME} is running."}


# ‚úÖ Route mounts (memory routes removed)
app.include_router(upload.router, prefix=settings.API_PREFIX)
app.include_router(project.router, prefix=settings.API_PREFIX)
app.include_router(background_tasks.router, prefix=settings.API_PREFIX)
app.include_router(session_log.router, prefix=settings.API_PREFIX)
app.include_router(ingest.router, prefix=settings.API_PREFIX)
app.include_router(chat.router, prefix=settings.API_PREFIX)


@app.on_event("startup")
async def start_background_ingestion():
    await ingestion_worker.startup_event()


# üîÅ Patch ingestion worker to debug missing file inserts
import asyncio
import logging
import uuid
from datetime import datetime

from app.core.supabase_client import supabase
from app.api.file_ops.ingest import process_file

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger("ingestion_worker")

BUCKET = "maxgptstorage"
CHECK_INTERVAL = 300


async def run_ingestion_loop():
    while True:
        try:
            logger.info("üîÅ Starting ingestion cycle")

            user_folders = supabase.storage.from_(BUCKET).list("")
            if not user_folders:
                logger.info("üì≠ No user folders found in storage bucket.")
                await asyncio.sleep(CHECK_INTERVAL)
                continue

            for folder in user_folders:
                user_id = folder["name"].rstrip("/")
                logger.info(f"üìÇ Scanning user folder: {user_id}")

                all_files = supabase.storage.from_(BUCKET).list(f"{user_id}/", {"recursive": True})
                for file in all_files:
                    logger.info(f"üßæ Found file: {file['name']}")
                    path_parts = file["name"].split("/")
                    if len(path_parts) != 3:
                        logger.warning(f"‚ö†Ô∏è Skipping malformed path: {file['name']}")
                        continue

                    user_id, project_name, file_name = path_parts
                    file_path = f"{user_id}/{project_name}/{file_name}"
                    logger.info(f"üîç Checking for file_path: {file_path}")

                    exists = (
                        supabase.table("files")
                        .select("id")
                        .eq("file_path", file_path)
                        .maybe_single()
                        .execute()
                    )

                    if not exists.data:
                        logger.info(f"‚ûï New file found: {file_path}. Registering.")
                        project_lookup = (
                            supabase.table("projects")
                            .select("id")
                            .eq("user_id", user_id)
                            .eq("name", project_name)
                            .maybe_single()
                            .execute()
                        )

                        if not project_lookup.data:
                            logger.warning(f"‚ö†Ô∏è No matching project for {project_name} under {user_id}")
                            continue

                        project_id = project_lookup.data["id"]
                        file_id = str(uuid.uuid4())

                        record = {
                            "id": file_id,
                            "file_path": file_path,
                            "file_name": file_name,
                            "user_id": user_id,
                            "project_id": project_id,
                            "uploaded_at": datetime.utcnow().isoformat(),
                            "ingested": False,
                            "ingested_at": None,
                        }
                        logger.info(f"üì¶ Attempting to insert: {record}")
                        insert_result = supabase.table("files").insert(record).execute()
                        if getattr(insert_result, "error", None):
                            logger.error(f"‚ùå Insert error: {insert_result.error.message}")
                        else:
                            logger.info(f"‚úÖ Inserted file metadata for {file_path}")

            unprocessed = (
                supabase.table("files")
                .select("id, file_path, user_id")
                .eq("ingested", False)
                .limit(20)
                .execute()
            )

            for file in unprocessed.data:
                try:
                    logger.info(f"üß† Ingesting {file['file_path']}")
                    process_file(file_path=file["file_path"], file_id=file["id"], user_id=file["user_id"])
                except Exception as e:
                    logger.error(f"‚ùå Failed to ingest {file['file_path']}: {e}")

            logger.info("‚úÖ Ingestion cycle complete.")

        except Exception as e:
            logger.exception(f"üí• Unexpected ingestion error: {e}")

        await asyncio.sleep(CHECK_INTERVAL)


async def startup_event():
    asyncio.create_task(run_ingestion_loop())
