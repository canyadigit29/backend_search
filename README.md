# Backend Search - Document Search & RAG System.


A production-ready FastAPI backend for document processing, semantic search, and GPT-powered question answering. Built for integration with Custom GPTs and real-world document management workflows.

## ğŸš€ Features

### Core Functionality
- **Document Upload & Processing**: Automated OCR, chunking, and embedding pipeline
- **Semantic Search**: Hybrid search combining vector similarity and keyword matching
- **GPT Integration**: Direct API endpoints for Custom GPT assistants
- **Google Drive Sync**: Automated file synchronization and processing
- **Background Workers**: Efficient processing of documents and OCR tasks

### Search Capabilities
- Vector similarity search using OpenAI embeddings
- Full-text search with PostgreSQL
- Hybrid scoring with configurable weights
- Intelligent query understanding and filtering
- Batch processing for large result sets

## ğŸ—ï¸ Architecture

```
app/
â”œâ”€â”€ api/
â”‚   â”œâ”€â”€ assistant/          # Custom GPT integration endpoints
â”‚   â”œâ”€â”€ file_ops/          # Document processing and search
â”‚   â””â”€â”€ gdrive_ops/        # Google Drive synchronization
â”œâ”€â”€ core/                  # Core services and utilities
â”œâ”€â”€ services/             # Business logic services
â””â”€â”€ workers/              # Background task processing
```

## ğŸ› ï¸ Technology Stack

- **Framework**: FastAPI with async support
- **Database**: PostgreSQL with pgvector for embeddings
- **Storage**: Supabase for file storage and database
- **AI/ML**: OpenAI GPT-5 and embeddings
- **Document Processing**: OCR with Tesseract, PDF processing
- **Deployment**: Railway (production) with Docker support

## ğŸ“‹ Prerequisites

- Python 3.11+
- PostgreSQL with pgvector extension
- Supabase account and project
- OpenAI API key
- Google Drive API credentials (optional)

## ğŸš€ Quick Start

1. **Clone and setup environment**:
```bash
git clone https://github.com/canyadigit29/backend_search.git
cd backend_search
python -m venv .venv
source .venv/bin/activate  # On Windows: .venv\Scripts\activate
pip install -r requirements.txt
```

2. **Configure environment variables**:
```bash
cp .env.example .env
# Edit .env with your credentials
```

3. **Run the application**:
```bash
uvicorn app.main:app --reload
```

4. **Start background workers**:
```bash
# OCR and document processing
python run_worker.py

# Google Drive sync (optional)
python run_gdrive_sync.py
```

## ğŸ”§ Configuration

### Environment Variables
```env
# Database
SUPABASE_URL=your_supabase_url
SUPABASE_SERVICE_ROLE=your_service_role_key

# OpenAI
OPENAI_API_KEY=your_openai_key

# Google Drive (optional)
GOOGLE_DRIVE_FOLDER_ID=your_folder_id
GOOGLE_SERVICE_ACCOUNT_KEY=path_to_service_account.json

# API Configuration
API_PREFIX=/api
ALLOWED_ORIGINS=https://your-frontend.com
```

## ğŸ“¡ API Endpoints

### Search Documents
```http
POST /api/assistant/search_docs
Content-Type: application/json

{
  "query": "your search query",
  "relevance_threshold": 0.4,
  "max_results": 100,
  "search_weights": {
    "semantic": 0.6,
    "keyword": 0.4
  }
}
```

### Google Drive Sync
```http
POST /api/gdrive/sync
```

### Manual Worker Trigger
```http
POST /api/run-worker
```

## ğŸ”„ Background Processing

The system includes automated background workers that run every hour:

- **OCR Worker**: Processes uploaded PDFs for text extraction
- **Ingestion Worker**: Chunks and embeds documents for search
- **Google Drive Sync**: Downloads and processes new files from Google Drive

## ğŸ—ƒï¸ Database Schema

Key tables:
- `files`: Document metadata and processing status
- `document_chunks`: Text chunks with embeddings for search
- `embeddings`: Vector storage for semantic search

## ğŸ§ª Testing

```bash
python -m pytest tests/
```

## ğŸ“ Development

### Code Quality
- Type hints throughout
- Async/await for I/O operations
- Comprehensive error handling
- Structured logging

### Adding New Features
1. Core logic goes in `app/core/`
2. API endpoints in appropriate `app/api/` subdirectory
3. Background tasks in `app/workers/`
4. Update OpenAPI schema if needed

## ğŸš€ Deployment

### Railway (Recommended)
```bash
# Connect your GitHub repo to Railway
# Set environment variables in Railway dashboard
# Deploy automatically on push
```

### Docker
```bash
docker build -t backend-search .
docker run -p 8000:8000 backend-search
```

## ğŸ“Š Performance

- Optimized vector search with pgvector
- Efficient chunking and embedding strategies
- Configurable batch processing
- Background task processing to avoid API timeouts

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests if applicable
5. Submit a pull request

## ğŸ“„ License

This project is licensed under the MIT License.

## ğŸ†˜ Support

For issues and questions:
1. Check the [Issues](https://github.com/canyadigit29/backend_search/issues) page
2. Review the API documentation at `/docs` when running locally
3. Check the logs for detailed error information

---

Built with â¤ï¸ for efficient document search and AI integration.